---
title: "ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã¨undersampling + baggingã€æ­£ä¾‹:è² ä¾‹ã®æ¯”ç‡ã«ã‚ˆã‚‹èª¿æ•´"
emoji: "ğŸ¦¡"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["æ©Ÿæ¢°å­¦ç¿’", "scikitlearn", "Python"]
published: true
---

# æ¦‚è¦

æ©Ÿæ¢°å­¦ç¿’ã§ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’è¡Œã†éš›ã«ã‚¯ãƒ©ã‚¹é–“ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã«åã‚ŠãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆimbalanced dataï¼‰ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚’æ‰±ã†æ‰‹æ³•ã¨ã—ã¦undersampling + baggingãŒã‚ã‚Šã€ä»¥ä¸‹ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ã€‚

https://tjo.hatenablog.com/entry/2017/08/11/162057

æœ¬ç¨¿ã§ã¯ã€undersampling + baggingã‚’è©¦ã—ã€undersamplingã®éš›ã«æ­£ä¾‹:è² ä¾‹ã®æ¯”ç‡ã‚’æ“ä½œã—ã¦æ¤œçŸ¥æ€§èƒ½ã®èª¿æ•´ã‚’è©¦ã—ã¦ã¿ãŸã€‚

# undersampling + bagging

undersampling + baggingã¯ä»¥ä¸‹ã®è«–æ–‡ãŒã‚ªãƒªã‚¸ãƒŠãƒ«ã§ã‚ã‚‹ã€‚

> B. C. Wallace, K. Small, C. E. Brodley and T. A. Trikalinos, "Class Imbalance, Redux," 2011 IEEE 11th International Conference on Data Mining, 2011, pp. 754-763, doi: 10.1109/ICDM.2011.33.


https://doi.org/10.1109/ICDM.2011.33


è©³ç´°ã«ã¤ã„ã¦ã¯ã€ä¸Šè¨˜ã‚’èª­ã‚“ã§ã„ãŸã ãã¨ã—ã¦ã€ç°¡å˜ãªèª¬æ˜ã¨ã—ã¦ã¯ã€ä¸Šè¨˜è«–æ–‡ã®è‘—è€…ã®ä¸€äººã®C. E. BrodleyãŒ2015å¹´ã«[è¬›ç¾©ã—ãŸéš›](https://course.ccs.neu.edu/cs6140sp15/schedulen_mod_Spring2015.html)ã®è³‡æ–™ãŒã‚ã‹ã‚Šã‚„ã™ã„ã€‚

https://course.ccs.neu.edu/cs6140sp15/4_boosting/slides/wallace_imbalance_icdm_11_for_class_2012_final.pptx
â€» pptæ³¨æ„

ä»¥ä¸‹ã§ã¯ã“ã®è³‡æ–™ã®å›³ã«åŸºã¥ã„ã¦èª¬æ˜ã™ã‚‹ã€‚ï¼ˆå…¨ã¦ã®å›³ã®å¼•ç”¨å…ƒã¯ä¸Šè¨˜ã®è¬›ç¾©è³‡æ–™ã§ã‚ã‚‹ï¼‰

## ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã®å•é¡Œç‚¹

ä»¥ä¸‹ã®ã‚ˆã†ãªä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®æ¨™æœ¬ã‚’ä»®å®šã™ã‚‹ã€‚

![](/images/dd54a797cc1972/ib1.png)

çœŸã®å¢ƒç•Œã¯w*ã§ç¤ºã—ãŸã‚‚ã®ã§ã‚ã‚‹ãŒã€é™ã‚‰ã‚ŒãŸæ¨™æœ¬ã‹ã‚‰ã¯åã£ãŸå¢ƒç•ŒW^ãŒå¾—ã‚‰ã‚Œã¦ã—ã¾ã†ã€‚

![](/images/dd54a797cc1972/ib2.png)

ä¸€æ¬¡å…ƒã§è¡¨ç¾ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ã€‚

![](/images/dd54a797cc1972/ib3.png)

æ¨™æœ¬ã®æ•°ãŒå°‘ãªãã€Pã§è¡¨ã—ãŸåˆ†å¸ƒã®ä¸€éƒ¨ã—ã‹è¦³å¯Ÿã§ãã¦ã„ãªã„ï¼ˆã‚‚ã£ã¨å³å´ã®xãŒå¿…è¦ï¼‰ãŸã‚ã€åã£ãŸå¢ƒç•ŒW^ãŒå¾—ã‚‰ã‚Œã¦ã—ã¾ã†ã€‚

![](/images/dd54a797cc1972/ib4.png)

## ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ãªãã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ç†ç”±

ä¸Šè¨˜ã®minority classã«å¯¾ã—ã¦ã€ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆSMOTE; Synthetic Minority Oversamping Techniqueï¼‰ã‚’å®Ÿæ–½ã—ãŸã¨ã—ã‚ˆã†ã€‚

SMOTEã¯ã€è¦³æ¸¬ã•ã‚ŒãŸæ¨™æœ¬åŒå£«ã®å†…æŒ¿ã«ã‚ˆã‚Šã€åˆæˆã•ã‚ŒãŸæ¨™æœ¬ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚

![](/images/dd54a797cc1972/smote1.png)

æ¬¡ã®å›³ã§è¦³æ¸¬ã•ã‚ŒãŸæ¨™æœ¬åŒå£«ã§å†…æŒ¿ã—ãŸå ´åˆã€

![](/images/dd54a797cc1972/smote2.png)

ä»¥ä¸‹ã®ã‚ˆã†ã«ã€ï¼’ã¤ã®xé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã‚‹ã ã‘ã§ã€åã£ãŸå¢ƒç•ŒW^ã‚’ä¿®æ­£ã§ããªã„ã€‚

![](/images/dd54a797cc1972/smote3.png)


## ãƒã‚®ãƒ³ã‚°ãŒæœ‰åŠ¹ãªç†ç”±

majority classã®ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ç¹°ã‚Šè¿”ã—ã¦å¤šãã®å¢ƒç•Œwã‚’å€™è£œã¨ã™ã‚‹ã“ã¨ã§ã€çœŸã®å¢ƒç•Œw*ã¨åŒç­‰ã®åˆ†é¡ã‚’æ„å›³ã—ãŸã‚‚ã®ãŒãƒã‚®ãƒ³ã‚°ã§ã‚ã‚‹ã€‚

![](/images/dd54a797cc1972/bag1.png)

ä»¥ä¸‹ã®ã‚ˆã†ã«ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ãã€‚

![](/images/dd54a797cc1972/bag2.png)
![](/images/dd54a797cc1972/bag3.png)
![](/images/dd54a797cc1972/bag4.png)
![](/images/dd54a797cc1972/bag5.png)

ä»¥ä¸‹ã®ã‚ˆã†ã«ç¹°ã‚Šè¿”ã—ã¦å¾—ã‚‰ã‚ŒãŸå¢ƒç•Œã¯åã‚Šã‚’å°‘ãªãã—ã¦ã„ã‚‹ã€‚

![](/images/dd54a797cc1972/bag6.png)

ä»¥ä¸ŠãŒã€ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã›ãšã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ã‹ã¤ãƒã‚®ãƒ³ã‚°ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ï¼ˆundersampling + baggingï¼‰ãŒæœ‰åŠ¹ã¨ã•ã‚Œã¦ã„ã‚‹ç†ç”±ã§ã‚ã‚‹ã€‚

# ä¾‹

ã“ã“ã§ã¯ã€[Classification on imbalanced data Â |Â  TensorFlow Core](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)ã«å‡ºã¦ãã‚‹Kaggleã® [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)ã‚’ä½¿ã£ã¦ã€undersampling + baggingã‚’è©¦ã—ã¦ã¿ãŸã€‚æ¤œçŸ¥æ€§èƒ½ã®ç®—å‡ºãªã©ã‚‚[Classification on imbalanced data Â |Â  TensorFlow Core](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)ã®æ–¹æ³•ã«æº–ã˜ãŸã‚‚ã®ã«ã—ãŸã€‚

notebookå…¨ä½“ã¯ä»¥ä¸‹ã«å…¬é–‹ã—ãŸã®ã§å‚ç…§ã„ãŸã ããŸã„ã€‚
https://gist.github.com/kn1kn1/5a7843a58bd3dc9db91aa28862be6fa9

å…ƒã®è¨˜äº‹ã§ã¯ã€random seedãŒå›ºå®šã•ã‚Œã¦ãŠã‚‰ãšã€å®Ÿè¡Œã™ã‚‹ãŸã³ã«ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãŒè¡Œã‚ã‚Œã¦ã„ãŸãŸã‚ã€ä»¥ä¸‹ã®éƒ¨åˆ†ã§è¨­å®šã™ã‚‹ã‚ˆã†å¤‰æ›´ã—ãŸã€‚

```
# Use a utility from sklearn to split and shuffle your dataset.
train_df, test_df = train_test_split(cleaned_df, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)
```

å°šã€random seedã‚’å›ºå®šã—ãŸçŠ¶æ…‹ã§å…ƒã®è¨˜äº‹ã®notebookï¼ˆkerasã«ã‚ˆã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªNNï¼‰ã‚’å®Ÿè¡Œã—ãŸã‚‚ã®ãŒä»¥ä¸‹ã§ã‚ã‚‹ã€‚

https://gist.github.com/kn1kn1/faa3e8b78afcfb26d2925642f3f7a922

ã“ã“ã§ã¯ã€ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã«åŠ ãˆã€kerasç”¨ã«ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ã„ã‚‹ã€‚

```
import random
import numpy as np
import tensorflow as tf

seed = 42
random.seed(seed)
np.random.seed(seed)
tf.random.set_seed(seed)
```


## ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—

ã§ã¯ã€æœ€åˆã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã›ãšã«ãƒã‚®ãƒ³ã‚°ã®ã¿ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®çµæœã‚’è¦‹ã¦ã¿ã‚ˆã†ã€‚

ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ä»¥ä¸‹ã§ã‚ã‚‹ã€‚random_stateã®æŒ‡å®šã€n_jobsã®æŒ‡å®šï¼ˆã‚³ã‚¢ã‚’å…¨ã¦ä½¿ã†ï¼‰ä»¥å¤–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚ã‚‹ã€‚

```
from sklearn.ensemble import RandomForestClassifier

neg, pos = np.bincount(train_labels)
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))
train_f_count = neg
train_t_count = pos

classifier = RandomForestClassifier(
    random_state = 42,
    n_jobs = -1
)

classifier.fit(train_df, train_labels)
```

ä»Šå›ã®ãƒ‡ãƒ¼ã‚¿ã ã¨Minorityï¼ˆæ­£ä¾‹ï¼‰ãŒ330ä»¶ã«å¯¾ã—ã€Majorityï¼ˆè² ä¾‹ï¼‰ãŒ182,276ä»¶ã§ã€Minority:Majorityï¼ˆæ­£ä¾‹:è² ä¾‹ï¼‰ã¯ã€1:552ã§ã‚ã£ãŸã€‚

Confusion Matrixã¯ä»¥ä¸‹ã§ã‚ã‚‹ã€‚ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã‚ˆãã‚ã‚‹ã®ã¯ã€Trueã®äºˆæ¸¬ãŒå…¨ãç„¡ãTPãŒå…¨ãç„¡ã„çµæœã ã£ãŸã‚Šã™ã‚‹ãŒã€ãã®ã‚ˆã†ãªçŠ¶æ³ã§ã¯ãªã„ã‚ˆã†ã ã€‚**FPãŒå°‘ãªãã€FNãŒå¤šã„**ç‚¹ã«æ³¨æ„ã€‚

![](/images/dd54a797cc1972/cm1.png)


## æ­£ä¾‹:è² ä¾‹ã‚’1:1ã«ã™ã‚‹

æ¬¡ã«ã€Minority:Majorityï¼ˆæ­£ä¾‹:è² ä¾‹ï¼‰ã‚’1:1ã§è©¦ã—ã¦ã¿ã‚‹ã€‚ã“ã®ä¾‹ã ã¨Majorityï¼ˆè² ä¾‹ï¼‰ãŒ182,276ä»¶ã‚ã‚‹ã®ã§ã€ã“ã‚Œã‚’Minorityï¼ˆæ­£ä¾‹ï¼‰ã®æ•°330ã¨åŒæ•°ã¾ã§ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚

```
from imblearn.pipeline import Pipeline
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier

neg, pos = np.bincount(train_labels)
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))
train_f_count = neg
train_t_count = pos

under_sampling_rate = 1
sampler = RandomUnderSampler(
    sampling_strategy = {0 : int(train_t_count * under_sampling_rate), 1 : train_t_count}, 
    random_state = 42
)

classifier = RandomForestClassifier(
    random_state = 42,
    n_jobs = -1
)

train_res_df, train_res_labels = sampler.fit_resample(train_df, train_labels)
classifier.fit(train_res_df, train_res_labels)
```

Confusion Matrixã¯ä»¥ä¸‹ã§ã‚ã‚‹ã€‚**FPãŒéå¸¸ã«å¤šãã€FNãŒæ¯”è¼ƒçš„å°‘ãªã„**çµæœã«ãªã£ãŸã€‚

![](/images/dd54a797cc1972/cm2.png)

ã“ã“ã§ã®çŠ¶æ³ã¯ã€[Undersampling + baggingã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾å‡¦ã—ãŸéš›ã®äºˆæ¸¬ç¢ºç‡ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è£œæ­£ã—ã¦ã€ãã®çµæœã‚’å¯è¦–åŒ–ã—ã¦ã¿ã‚‹ - æ¸‹è°·é§…å‰ã§åƒããƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ãƒ–ãƒ­ã‚°](https://tjo.hatenablog.com/entry/2019/08/04/150431) ã§TJOã•ã‚“ã®ä»°ã£ã¦ã„ã‚‹

> ã€Œundersampling + baggingã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’è£œæ­£ã™ã‚‹ã¨false positiveã¯ç‰©å‡„ãå¤šããªã‚‹ã€

ã¨åŒæ§˜ã®ã‚±ãƒ¼ã‚¹ã¨æ€ã‚ã‚Œã‚‹ã€‚

## æ­£ä¾‹:è² ä¾‹ã®æ¯”ç‡ã«ã‚ˆã‚‹ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ

æ¬¡ã«ã€Minority:Majorityï¼ˆæ­£ä¾‹:è² ä¾‹ï¼‰ã®æ¯”ç‡ã‚’1:1ã€œ1:10ã¾ã§èª¿æ•´ã—ãŸçµæœã‚’è¦‹ã¦ã¿ã‚ˆã†ã€‚

![](/images/dd54a797cc1972/grid_search.png)

f1, precision, recallã‚’ãã‚Œãã‚Œãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã„ã‚‹ãŒã€

- f1, recallé‡è¦–ã§ã‚ã‚Œã°ratio=1
- precisioné‡è¦–ã§ã‚ã‚Œã°ratio=7

ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã§ã‚ã‚‹ã€‚

ã¾ãŸã€å…¨ä½“çš„ãªå‚¾å‘ã¨ã—ã¦ã¯ã€

- Majorityï¼ˆè² ä¾‹ï¼‰ãŒå¢—ãˆã‚‹ã¨FNãŒå¢—ãˆã€FPãŒæ¸›ã‚‹
- Minorityï¼ˆæ­£ä¾‹ï¼‰ãŒå¢—ãˆã‚‹ã¨FNãŒæ¸›ã‚Šã€FPãŒå¢—ãˆã‚‹

ã¨ã„ã†ã“ã¨ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚

## æ­£ä¾‹:è² ä¾‹ã‚’1:7ã«ã™ã‚‹

ã¨ã„ã†ã‚ã‘ã§ã€Minority:Majorityï¼ˆæ­£ä¾‹:è² ä¾‹ï¼‰=1:7ã‚’è©¦ã—ã¦ã¿ã‚ˆã†ã€‚

```
from imblearn.pipeline import Pipeline
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier

neg, pos = np.bincount(train_labels)
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))
train_f_count = neg
train_t_count = pos

under_sampling_rate = 7
sampler = RandomUnderSampler(
    sampling_strategy = {0 : int(train_t_count * under_sampling_rate), 1 : train_t_count}, 
    random_state = 42
)

classifier = RandomForestClassifier(
    random_state = 42,
    n_jobs = -1
)

train_res_df, train_res_labels = sampler.fit_resample(train_df, train_labels)
classifier.fit(train_res_df, train_res_labels)
```

1:1ã¨æ¯”è¼ƒã™ã‚‹ã¨ã€FPã®æ•°ãŒã ã„ã¶å°‘ãªããªã£ãŸã€‚

![](/images/dd54a797cc1972/cm3.png)

ã“ã®æ€§èƒ½ãŒå¦¥å½“ã‹ã©ã†ã‹ã¯ã€å®Ÿå‹™ã«ãŠã„ã¦ã¯ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ï¼ˆFNãŒçµ¶å¯¾ã«è¨±å®¹ã•ã‚Œãªã„ã®ã‹ã€FPãŒå¤šã„ã“ã¨ãŒå•é¡Œã«ãªã‚‹ã‹ï¼‰å¦‚ä½•ã¨æ€ã‚ã‚Œã‚‹ãŒã€æ­£ä¾‹:è² ä¾‹ã®æ¯”ç‡ã‚’æ“ä½œã™ã‚‹ã“ã¨ã§ã€precision, recallã‚’èª¿æ•´ã§ããã†ãªã“ã¨ã¯åˆ†ã‹ã£ãŸã€‚

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ROCæ›²ç·šã‚’è¦‹ã‚‹ã¨å…¨ä½“çš„ã«éå­¦ç¿’ãªã®ã§ã€ã“ã“ã‹ã‚‰åˆ¥é€”max_features, min_samples_split, min_samples_leaf, max_depthã¨ã„ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§èª¿æ•´ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚

![](/images/dd54a797cc1972/roc.png)


## reference

- [ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’undersampling + baggingã§è£œæ­£ã™ã‚‹ã¨æ±åŒ–æ€§èƒ½ã‚‚ç¢ºä¿ã§ãã¦è‰¯ã•ãã† - æ¸‹è°·é§…å‰ã§åƒããƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ãƒ–ãƒ­ã‚°](https://tjo.hatenablog.com/entry/2017/08/11/162057)
- [Undersampling + baggingã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾å‡¦ã—ãŸéš›ã®äºˆæ¸¬ç¢ºç‡ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è£œæ­£ã—ã¦ã€ãã®çµæœã‚’å¯è¦–åŒ–ã—ã¦ã¿ã‚‹ - æ¸‹è°·é§…å‰ã§åƒããƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ãƒ–ãƒ­ã‚°](https://tjo.hatenablog.com/entry/2019/08/04/150431) 
- B. C. Wallace, K. Small, C. E. Brodley and T. A. Trikalinos, "Class Imbalance, Redux," 2011 IEEE 11th International Conference on Data Mining, 2011, pp. 754-763, doi: 10.1109/ICDM.2011.33.
  - https://doi.org/10.1109/ICDM.2011.33
- C. E. Brodleyã®è¬›ç¾©ãƒšãƒ¼ã‚¸
  - https://course.ccs.neu.edu/cs6140sp15/schedulen_mod_Spring2015.html
  - ãã®è³‡æ–™
    - https://course.ccs.neu.edu/cs6140sp15/4_boosting/slides/wallace_imbalance_icdm_11_for_class_2012_final.pptx


ä»¥ä¸‹ã¯ã€undersampling + baggingã«ã¤ã„ã¦ã¯å–ã‚Šä¸Šã’ã¦ã„ãªã„ãŒã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦æ¯”è¼ƒçš„ç°¡æ½”ã«æ›¸ã‹ã‚ŒãŸã‚‚ã®ã§ã€undersampling + baggingä»¥å¤–ã®æ‰‹æ³•ã‚’æ¤œè¨ã™ã‚‹éš›ã«ã‚‚ã—ã‹ã—ãŸã‚‰å½¹ã«ç«‹ã¤ã‹ã‚‚ã—ã‚Œãªã„ã€‚

- å¤§å´ ç¾ç©‚, ç§ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ï¼šä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿åˆ†é¡, äººå·¥çŸ¥èƒ½, 2022, 37 å·», 3 å·, p. 376-381, å…¬é–‹æ—¥ 2022/05/01, Online ISSN 2435-8614, Print ISSN 2188-2266, https://doi.org/10.11517/jjsai.37.3_376, https://www.jstage.jst.go.jp/article/jjsai/37/3/37_376/_article/-char/ja
- è—¤åŸå¹¸ä¸€ï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿è§£æã¨æ©Ÿæ¢°å­¦ç¿’ï¼Œpp. 296ï¼Œã‚ªãƒ¼ãƒ ç¤¾ï¼ˆ2022ï¼‰

ä»¥ä¸‹ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆé–¢é€£

- https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm
  - Leo Breimanã‚‰ã«ã‚ˆã‚‹è§£èª¬
  - Wikipediaã‹ã‚‰ã‚‚ã“ã¡ã‚‰ã«ç¹‹ãŒã£ã¦ã„ãªã‹ã£ãŸã‚ˆã†ãªã®ã§è¨˜è¼‰
  - `Random Forests(tm) is a trademark of Leo Breiman and Adele Cutler and is licensed exclusively to Salford Systems for the commercial release of the software. Our trademarks also include RF(tm), RandomForests(tm), RandomForest(tm) and Random Forest(tm).` ã ãã†
- https://mlu-explain.github.io/random-forest/
  - Amazonã®[Machine Learning University](https://aws.amazon.com/machine-learning/mlu/)ã‹ã‚‰æ´¾ç”Ÿã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
  - å€‹äººçš„ã«ã¯ç›´æ„Ÿçš„ã§ç†è§£ã—ã‚„ã™ã‹ã£ãŸ
